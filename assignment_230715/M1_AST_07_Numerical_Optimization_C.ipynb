{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Nwm4FK3wgU"
      },
      "source": [
        "# Advanced Programme in Deep Learning (Foundations and Applications)\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment 7: Numerical Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHj34EaN5oa5"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vPeurvKNAEz"
      },
      "source": [
        "At the end of the assignment, you will be able to\n",
        "\n",
        "*   understand about constrained optimization\n",
        "\n",
        "*   understand about Support Vector Machines\n",
        "\n",
        "*   understand the use of Lagrange Multiplers with multiple constraints  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWMVQWk58aXm"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqosl928dBA"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TIjwvQgQtP-C"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M1_AST_07_Numerical_Optimization_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer1():\n",
        "  try:\n",
        "    if not Answer1:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer1\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 1\")\n",
        "    return None\n",
        "\n",
        "def getAnswer2():\n",
        "  try:\n",
        "    if not Answer2:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer2\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 2\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgbAwtf6G6l5"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WCBUiz0oG6l6"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC                      # Importing Support vector classifier from sklearn\n",
        "from cvxopt import matrix as cvxopt_matrix\n",
        "from cvxopt import solvers as cvxopt_solvers\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import optimize\n",
        "from scipy.optimize import minimize, LinearConstraint           # Minimization of scalar function of one or more variables and Find the roots of a function\n",
        "from scipy.linalg import solve                                          # Solves the linear equation set a * x = b for the unknown x for square a matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgI_0qxdk7CJ"
      },
      "source": [
        "## Introduction to Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJY8ndIHk-yD"
      },
      "source": [
        "Optimization is an important tool in decision science and the analysis of physical systems. To make use of this tool, first identify some objective, a quantitative measure of the performance of the system under study. This objective could be profit, time, potential energy, or any quantity or combination of quantities that can be represented by a single number. The objective depends on certain characteristics of the system, called variables or unknowns. Here, the goal is to find the values of the variables that optimize the objective function.\n",
        "\n",
        "The process of identifying objective, variables, and constraints for a given problem is known as *modeling*. This step is mostly the first and the most important step in the optimization process. After an optimization algorithm has been applied to the model, we must be able to recognize whether it has succeeded in its task of finding a solution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGu-_eUqmiEW"
      },
      "source": [
        "#### Constrained optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozqgicu2mlZF"
      },
      "source": [
        "The general **constrained optimization** task is to maximize or minimize a function $f(x)$ by varying $x$, given certain constraints on $x$.\n",
        "\n",
        "Eg. Find minimum of $f(x_1,x_2,x_3) = x_1^2 + x_2^2 + x_3^2,  where \\lVert x_2\\rVert \\geq1$\n",
        "\n",
        "Eg. Designing the fastest vehicle with a constraint on fuel efficiency\n",
        "\n",
        "An optimization problem comprises of three basic components:\n",
        "\n",
        "- $x$: is the vector of variables, also called unknowns or parameters;\n",
        "- $f$: is the objective function, a (scalar) function of x that we want to maximize or\n",
        "minimize;\n",
        "- $c_i$: are constraint functions, which are scalar functions of x that define certain equations\n",
        "and inequalities that the unknown vector x must satisfy.\n",
        "\n",
        "Using this notation, the optimization problem can be written as follows:\n",
        "\n",
        "$\\min\\limits_{x \\in R^{N}}$ $f(x)$  \n",
        "\n",
        "$\\textrm{subject to}$ $\\hspace{1cm} c_i(x) = 0, \\hspace{0.25cm} i \\in \\xi$\n",
        "\n",
        "$\\hspace{2.75cm}$ $c_i(x)\\geq0, \\hspace{0.25cm} i \\in I$\n",
        "\n",
        "Here $I$ and $\\xi$ are sets of indices for equality and inequality constraints.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elxef7nTL7pI"
      },
      "source": [
        "#### Equality and Inequality Constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wdMUK1LMHAO"
      },
      "source": [
        "Consider the following general constrained optimization problem:\n",
        "\n",
        "$\\max\\limits_{x_i \\in R}$ $f(x_1,. . . . , x_n)$\n",
        "\n",
        "subject to:\n",
        "\n",
        "$g_1(x_1, . . . , x_n) \\leq b_1, . . . , g_k(x_1, . . . , x_n) \\leq b_k$,\n",
        "\n",
        "$h_1(x_1, . . . , x_n) = c_1, . . . , h_m(x_1, . . . , x_n) = c_m$\n",
        "\n",
        "The function $f(x)$ is called the objective function, $g(x)$ is called an *inequality constraint*, and $h(x)$ is called an *equality constraint*. In the above problem, there are $k$ *inequality constraints* and $m$ *equality constraints*. In the following, we will always assume that $f, g$, and h are $C^{1}$ functions, i.e. that they are differentiable and their derivatives are continuous.\n",
        "\n",
        "Notice that this problem differs from the regular unconstrained optimization problem instead of finding the maximum of $f(x)$ we are finding the maximum of $f(x)$ only over the points which satisfy the constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u4IUikm8tYx"
      },
      "source": [
        "\n",
        "### Example: Stockbroker Income"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnK3SV36gWjS"
      },
      "source": [
        "Let’s try a demonstration on how to use `minimize()`. Imagine you’re a stockbroker who’s interested in maximizing the total income from the sale of a fixed number of your stocks. You have identified a particular set of buyers, and for each buyer, you know the price they’ll pay and how much cash they have on hand.\n",
        "\n",
        "There is one constraint on the problem, which is that the sum of the total shares purchased by the buyers does not exceed the number of shares you have on hand. There are also bounds on each of the solution variables because each buyer has an upper bound of cash available, and a lower bound of zero. Negative solution x-values mean that you’d be paying the buyers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvyoazO52IWj"
      },
      "source": [
        "Steps we will follow to solve the problem:\n",
        "\n",
        "1. Initialize the variables\n",
        "\n",
        "2. Create arrays for storing price, money available with the buyers, and shares per buyer.\n",
        "\n",
        "3. Setting the constraints\n",
        "\n",
        "4. Setting the bounds\n",
        "\n",
        "5. Declaring the 'objective function'.\n",
        "\n",
        "6. Applying constrained optimization using minimize() method from scipy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZui-wK_wfKS"
      },
      "source": [
        "Solving Optimization Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seR9SIemgWjU"
      },
      "source": [
        "# set variables to determine the number of buyers in the market and the number of shares you want to sell\n",
        "n_buyers = 10\n",
        "n_shares = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH6bPIOZgWjU"
      },
      "source": [
        "Next, create arrays to store the price that each buyer pays for the shares, the maximum amount they can afford to spend, and the maximum number of shares each buyer can afford, given the first two arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSJyHMJegWjV"
      },
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "# Generating the array of prices the buyers will pay\n",
        "# np.random.random() creates an array of random numbers\n",
        "# on the half-open interval [0,1)\n",
        "prices = 100*np.random.random(n_buyers)\n",
        "\n",
        "# generate an array of integers on the half-open interval from [1, 4),\n",
        "# again with the size of the number of buyers\n",
        "money_available = 100*np.random.randint(1, 4, n_buyers)\n",
        "\n",
        "print(\"Price of the shares 1-{} : {}\".format(n_shares, prices))\n",
        "print(\"Money available with each buyer (1-{}): {}\".format(n_buyers, money_available))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CNdqXEkgWjV"
      },
      "source": [
        "Now, you need to compute the maximum number of shares each buyer can afford:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0LcA8jegWjV"
      },
      "source": [
        "# take the ratio of the money_available with prices to determine the maximum number of shares each buyer can purchase\n",
        "n_shares_per_buyer = money_available / prices\n",
        "\n",
        "print(\"No of shares per buyer:\\n\",n_shares_per_buyer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMIn-cn4gWjW"
      },
      "source": [
        "Now, you need to create the constraints and bounds for the solver.\n",
        "\n",
        " Remember that LinearConstraint takes the dot product of the input array with the solution values and compares it to the lower and upper bound. You can use this to set up the constraint on n_shares:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvbvwourgWjW"
      },
      "source": [
        "# create an array of ones with the length `n_buyers` as `LinearConstraint` takes the first argument as matrix\n",
        "# lb and ub are equal as it represents equality constraints\n",
        "# For example, a machine component may be required to move precisely by Δ to perform the desired operation,\n",
        "# so we must treat this as an equality constraint.\n",
        "constraint = LinearConstraint(np.ones(n_buyers), lb = n_shares, ub = n_shares)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCVXLHOJgWjW"
      },
      "source": [
        "Since `LinearConstraint` takes the dot product of the solution vector with this argument, it’ll result in the sum of the purchased shares.\n",
        "\n",
        "This result is then constrained to lie between the other two arguments:\n",
        "\n",
        "1. The lower bound lb\n",
        "2. The upper bound ub\n",
        "\n",
        "Next, create the bounds for the solution variable. The bounds limit the number of shares purchased to be 0 on the lower side and `n_shares_per_buyer` on the upper side. The format that `minimize()` expects for the bounds is a sequence of tuples of lower and upper bounds:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jVR7RERgWjW"
      },
      "source": [
        "bounds = [(0, n) for n in n_shares_per_buyer]\n",
        "bounds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXb3wCpBgWjX"
      },
      "source": [
        "# Here the objective function returns negative of dot product of 'x' declared as 'x0' below\n",
        "# and 'prices' which indicates that we are minimizing the value\n",
        "def objective_function(x, prices):\n",
        "    return -x.dot(prices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhUo-6KKgWjX"
      },
      "source": [
        "In this code, you define `objective_function()` to take two arguments. Then you take the dot product of x with prices and return the negative of that value. Remember that you have to return the negative because you’re trying to make that number as small as possible, or as close to negative infinity as possible. Finally, you can call `minimize()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAbLKfbqgWjY"
      },
      "source": [
        "res = minimize(\n",
        "    objective_function,\n",
        "    x0 = 10 * np.random.random(n_buyers),\n",
        "    args = (prices),\n",
        "    constraints=constraint,\n",
        "    bounds=bounds,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNIoWoXFgWjY"
      },
      "source": [
        "In this code, res is an instance of OptimizeResult, just like with `minimize_scalar()`. As you’ll see, there are many of the same fields, even though the problem is quite different. In the call to `minimize()`, you pass five arguments:\n",
        "\n",
        "1. objective_function\n",
        "2. $x_0$\n",
        "3. args\n",
        "4. constraints\n",
        "5. bounds\n",
        "\n",
        "Once the solver runs, you should inspect `res` by printing it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeOvD_6pgWjY"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGmdjppmgWjZ"
      },
      "source": [
        "You should also check and make sure that the constraints and bounds that you set are satisfied. You can do this with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrNRqCdJgWjZ"
      },
      "source": [
        "print(\"The total number of shares is:\", sum(res.x))\n",
        "print(\"Leftover money for each buyer:\", money_available - res.x * prices)\n",
        "print(\"Money Exhausted:\\n\",res.x * prices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement**\n",
        "\n",
        "Solve the problem of classification for linearly separable data, understand the concept of margin and get the essence of SVM (margin maximization)."
      ],
      "metadata": {
        "id": "S0AJnyDg5TMw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoBCr7X7S0Jd"
      },
      "source": [
        "### Introduction to Support Vector Machines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVx8dO706ps4"
      },
      "source": [
        "**Support vector machines** are a set of supervised learning methods used for classification, regression, and outliers detection.\n",
        "\n",
        "A simple linear SVM classifier works by making a straight line between two classes. That means all of the data points on one side of the line will represent a category and the data points on the other side of the line will be put into a different category. This means there can be an infinite number of lines to choose from.\n",
        "\n",
        "**Hyperplanes** are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes.\n",
        " * The hyperplane with maximum margin is called the optimal hyperplane.\n",
        "\n",
        "**Support vectors** are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane.\n",
        "\n",
        "**Margin** is the width that the boundary could be increased by before hitting a data point.\n",
        "\n",
        "![wget](https://cdn.talentsprint.com/aiml/aiml_2020_b14_hyd/experiment_details_backup/linear_data.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0DXXBDCQTng"
      },
      "source": [
        "#### Support Vector Machine Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Okaxfq9-P8q"
      },
      "source": [
        "**Algorithm for Linearly separable, binary classification problem**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjIPiwnC-gW6"
      },
      "source": [
        "Using the notation and steps provided by [Tristan Fletcher](https://static1.squarespace.com/static/58851af9ebbd1a30e98fb283/t/58902fbae4fcb5398aeb7505/1485844411772/SVM+Explained.pdf) the general steps to solve the SVM problem are the following:\n",
        "\n",
        "1. Create P where $H_{i,j}= y^{(i)}.y^{(j)}<x^{(i)}.x^{(j)}>$\n",
        "\n",
        "2. Calculate $w=\\sum_{i}^{m}y^{(i)} \\alpha_{i}x^{(i)}$\n",
        "\n",
        "3. Determine the set of support vectors S by finding the indices such that $\\alpha_{i}>0$\n",
        "\n",
        "4. Calculate the intercept term using $ b = \\frac{1}{N_{s}}\\sum_{s\\varepsilon  S} (y^{(s)}−\\sum_{m ∈ S} \\alpha_{m}y^{(m)}x^{(m)}.x^{(s)})$\n",
        "\n",
        "5. Each new point $x'$ is classified by evaluating $y′=sgn(w^{T}x′+b)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT_tX8aL_eLJ"
      },
      "source": [
        "#### Mapping the problem according to the quadratic solvers API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJsy2ebb_gpv"
      },
      "source": [
        "Since we will solve this optimization problem using the [CVXOPT](https://cvxopt.org/userguide/coneprog.html#quadratic-programming) library in python we will need to match the solver's API which, according to the documentation is of the form:\n",
        "\n",
        "\n",
        "\n",
        " $min \\frac{1}{2}x^{T}Px+q^{T}x$\n",
        "\n",
        "subject to  \n",
        "\n",
        "  * $Gx\\leq h$ and,\n",
        "  * $Ax=b$\n",
        "\n",
        "With API\n",
        "\n",
        "    cvxopt.solvers.qp(P, q[, G, h[, A, b[, solver[, initvals]]]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dual problem is expressed as:\n",
        "\n",
        "$max \\sum_{i=1}^{m} \\alpha_{i}−\\frac{1}{2}\\sum_{i,j}^{m} y^{(i)}y^{(j)} \\alpha_{i} \\alpha_{j}<x^{(i)}x^{(j)}>$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9qPs72Ne8sJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $H$ be a matrix such that $H_{i,j}= y^{(i)}y^{(j)}<x^{(i)}x^{(j)}>$, then the optimization becomes:\n",
        "\n",
        "\n",
        "$max \\sum_{i=1}^{m} \\alpha_{i}−\\frac{1}{2} \\alpha^{T} H \\alpha$,  subject to constraints $\\alpha_{i}\\geq0$  and $\\sum_{i=1}^{m}\\alpha_{i} y^{(i)}=0$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I1aiy_4v81Pg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert the sums into vector form and multiply both the objective and the constraint by −1 which turns this into a minimization problem and reverses the inequality\n",
        "\n",
        "$min \\frac{1}{2}\\alpha^{T}H\\alpha - 1^{T}\\alpha$\n",
        "subject to constraints $- \\alpha_{i}\\leq0$ and $y^{T}\\alpha = 0$\n",
        "\n"
      ],
      "metadata": {
        "id": "4PKvycf49DH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to convert our numpy arrays into the cvxopt format, using the same notation as in the documentation this gives\n",
        "\n",
        "P:  $H$ a matrix of size $m×m$\n",
        "\n",
        "q: $\\vec{-1}$  a vector of size $m×1$\n",
        "\n",
        "G: $−diag[1]$ a diagonal matrix of -1s of size $m×m$\n",
        "\n",
        "h: $\\vec{0}$  a vector of zeros of size $m×1$\n",
        "\n",
        "A: $y$ the label vector of size $m×1$\n",
        "\n",
        "b: $0$ a scalar"
      ],
      "metadata": {
        "id": "RGvaJAtS9j_P"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHWMp4tG_2MY"
      },
      "source": [
        "Note that in the simple example of $m=2$ the matrix $G$ and vector $h$ which define the constraint are\n",
        "\n",
        "$$G = \\begin{bmatrix}\n",
        "-1 & 0 \\\\\n",
        "0 & -1 \\\\\n",
        "\\end{bmatrix} and\n",
        "\\\\\n",
        "$$ $$h = \\begin{bmatrix}\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Wk_0WYITIK"
      },
      "source": [
        "#### Computing the matrix $H$ in vectorized form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KugagYs9IDLy"
      },
      "source": [
        "\n",
        "Consider the simple example with 2 input samples $(\\left\\{x^{(1)}, x^{(2)}\\right\\} \\in \\mathbb{R}^{2})$ which are two dimensional vectors. i.e. $\n",
        "x^{(1)}=\\left(x_{1}^{(1)}, x_{2}^{(1)}\\right)^{T}$\n",
        "\n",
        "$$X = \\begin{bmatrix}\n",
        "x^{(1)}_{1} & x^{(1)}_{2} \\\\\n",
        "x^{(2)}_{1} & x^{(2)}_{2} \\\\\n",
        "\\end{bmatrix}, y = \\begin{bmatrix}\n",
        "y^{(1)}\\\\\n",
        "y^{(2)}\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "We now proceed to creating a new matrix $X$ where each input sample $x$ is multiplied by the coresponding output label $y$.\n",
        "This can be done easily in Numpy using vectorization and padding.\n",
        "\n",
        "$$X' = \\begin{bmatrix}\n",
        "x^{(1)}_{1}y^{(1)} & x^{(1)}_{2}y^{(1)} \\\\\n",
        "x^{(2)}_{1}y^{(2)} & x^{(2)}_{2}y^{(2)} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Finally we take the **matrix multiplication** of $X′$ and its transpose giving $H=X'X'T$\n",
        "\n",
        "\n",
        "$$H = X'@X'^{T} = \\begin{bmatrix}\n",
        "x^{(1)}_{1}y^{(1)} & x^{(1)}_{2}y^{(1)} \\\\\n",
        "x^{(2)}_{1}y^{(2)} & x^{(2)}_{2}y^{(2)} \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x^{(1)}_{1}y^{(1)} & x^{(2)}_{1}y^{(2)} \\\\\n",
        "x^{(1)}_{2}y^{(1)} & x^{(2)}_{2}y^{(2)} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "\n",
        "$$\n",
        "H = \\begin{bmatrix}\n",
        "x_{1}^{(1)} x_{1}^{(1)} y^{(1)} y^{(1)}+x_{2}^{(1)} x_{2}^{(1)} y^{(1)} y^{(1)} & x_{1}^{(1)} x_{1}^{(2)} y^{(1)} y^{(2)}+x_{2}^{(1)} x_{2}^{(2)} y^{(1)} y^{(2)} \\\\\n",
        "x_{1}^{(2)} x_{1}^{(1)} y^{(2)} y^{(1)}+x_{2}^{(2)} x_{2}^{(1)} y^{(2)} y^{(1)} & x_{1}^{(2)} x_{1}^{(2)} y^{(2)} y^{(2)}+x_{2}^{(2)} x_{2}^{(2)} y^{(2)} y^{(2)}\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating custom dataset"
      ],
      "metadata": {
        "id": "VnofeC6AnHDb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oap46TSbUbRy"
      },
      "source": [
        "Let us create the custom data for our problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAPZ85tV1Dmq"
      },
      "source": [
        "# Creating data points\n",
        "x_neg = np.array([[3,4],[1,4],[2,3]])\n",
        "y_neg = np.array([-1,-1,-1])\n",
        "x_pos = np.array([[6,-1],[7,-1],[5,-3]])\n",
        "y_pos = np.array([1,1,1])\n",
        "x1 = np.linspace(-10,10)\n",
        "x = np.vstack((np.linspace(-10,10),np.linspace(-10,10)))\n",
        "\n",
        "# Data for the next section\n",
        "X = np.vstack((x_pos, x_neg))\n",
        "y = np.concatenate((y_pos,y_neg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters (weight and bias) guessed by inspection\n",
        "w = np.array([1,-1]).reshape(-1,1)\n",
        "b = -3"
      ],
      "metadata": {
        "id": "9DyDHXgkSBmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Representing Support Vectors and Hyperplane"
      ],
      "metadata": {
        "id": "tw8HWc-Op8xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us plot the figure for representing the support vectors and drawing hyperplane to show whether the points are linearly separable or not."
      ],
      "metadata": {
        "id": "6j6602CUT4wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the plot\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "plt.scatter(x_neg[:,0], x_neg[:,1], marker = 'x', color = 'r', label = 'Negative -1')\n",
        "plt.scatter(x_pos[:,0], x_pos[:,1], marker = 'o', color = 'b',label = 'Positive +1')\n",
        "plt.plot(x1, x1  - 3, color = 'darkblue')\n",
        "plt.plot(x1, x1  - 7, linestyle = '--', alpha = .3, color = 'b')\n",
        "plt.plot(x1, x1  + 1, linestyle = '--', alpha = .3, color = 'r')\n",
        "plt.xlim(0,10)\n",
        "plt.ylim(-5,5)\n",
        "plt.xticks(np.arange(0, 10, step=1))\n",
        "plt.yticks(np.arange(-5, 5, step=1))\n",
        "\n",
        "# Adding the margin lines\n",
        "plt.axvline(0, color = 'black', alpha = .5)\n",
        "plt.axhline(0,color = 'black', alpha = .5)\n",
        "plt.plot([2,6],[3,-1], linestyle = '-', color = 'darkblue', alpha = .5 )\n",
        "plt.plot([4,6],[1,1],[6,6],[1,-1], linestyle = ':', color = 'darkblue', alpha = .5 )\n",
        "plt.plot([0,1.5],[0,-1.5],[6,6],[1,-1], linestyle = ':', color = 'darkblue', alpha = .5 )\n",
        "\n",
        "# Annotations\n",
        "plt.annotate('$A \\ (6,-1)$', xy = (5,-1), xytext = (6,-1.5))\n",
        "plt.annotate('$B \\ (2,3)$', xy = (2,3), xytext = (2,3.5)) #, arrowprops = {'width':.2, 'headwidth':8})\n",
        "plt.annotate('$2$', xy = (5,1.2), xytext = (5,1.2) )\n",
        "plt.annotate('$2$', xy = (6.2,.5), xytext = (6.2,.5))\n",
        "plt.annotate('$2\\sqrt{2}$', xy = (4.5,-.5), xytext = (4.5,-.5))\n",
        "plt.annotate('$2\\sqrt{2}$', xy = (2.5,1.5), xytext = (2.5,1.5))\n",
        "plt.annotate('$w^Tx + b = 0$', xy = (8,4.5), xytext = (8,4.5))\n",
        "plt.annotate('$(\\\\frac{1}{4},-\\\\frac{1}{4}) \\\\binom{x_1}{x_2}- \\\\frac{3}{4} = 0$', xy = (7.5,4), xytext = (7.5,4))\n",
        "plt.annotate('$\\\\frac{3}{\\sqrt{2}}$', xy = (.5,-1), xytext = (.5,-1))\n",
        "\n",
        "# Labels and showing the plot\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "62Lzy1JlSFhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Declaration of Parameters"
      ],
      "metadata": {
        "id": "LRfgtgQRqI1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing values and computing $H$. Note that the 1. is used to convert y to float type.\n"
      ],
      "metadata": {
        "id": "g1dtoMgQUFlJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uef2XWrJ1O9i"
      },
      "source": [
        "# Shape of the data points\n",
        "m, n = X.shape\n",
        "\n",
        "# Reshaping y column\n",
        "y = y.reshape(-1,1) * 1.\n",
        "\n",
        "# Input to the H matrix\n",
        "X_dash = y * X\n",
        "H = np.dot(X_dash , X_dash.T) * 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into cvxopt format\n",
        "P = cvxopt_matrix(H)\n",
        "q = cvxopt_matrix(-np.ones((m, 1)))\n",
        "G = cvxopt_matrix(-np.eye(m))\n",
        "h = cvxopt_matrix(np.zeros(m))\n",
        "A = cvxopt_matrix(y.reshape(1, -1))\n",
        "b = cvxopt_matrix(np.zeros(1))"
      ],
      "metadata": {
        "id": "_tSudhE8SgXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the solver parameters (change default to decrease tolerance)\n"
      ],
      "metadata": {
        "id": "Yii3-G2EUY1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cvxopt_solvers.options['show_progress'] = False\n",
        "cvxopt_solvers.options['abstol'] = 1e-10\n",
        "cvxopt_solvers.options['reltol'] = 1e-10\n",
        "cvxopt_solvers.options['feastol'] = 1e-10"
      ],
      "metadata": {
        "id": "4cLy8HD2SgLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Computation"
      ],
      "metadata": {
        "id": "H-MgHNQVqef_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us run the solver method in order to compute values of alpha, so that, it can be used further to compute w and b."
      ],
      "metadata": {
        "id": "maf_wTj8qpF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run solver and find the values of alpha\n",
        "sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
        "alphas = np.array(sol['x'])"
      ],
      "metadata": {
        "id": "_D83Y-6jUjVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I8epqbNUqcb"
      },
      "source": [
        "Further, we will be computing the value w and b parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPDFY-J42Bkd"
      },
      "source": [
        "# w parameter in vectorized form\n",
        "w = ((y * alphas).T @ X).reshape(-1,1)\n",
        "\n",
        "# Selecting the set of indices S corresponding to non zero parameters\n",
        "S = (alphas > 1e-4).flatten()\n",
        "\n",
        "# Computing b\n",
        "b = y[S] - np.dot(X[S], w)\n",
        "\n",
        "# Display results\n",
        "print('Alphas = ',alphas[alphas > 1e-4])\n",
        "print('w = ', w.flatten())\n",
        "print('b = ', b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8bfOpu3414T"
      },
      "source": [
        "# Selecting the alphas for support vectors\n",
        "support_vector_boolean = (alphas > 1e-4).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3omFTluN5Ctq"
      },
      "source": [
        "print(\"Following are the support vectors:\\n{}\".format(X[support_vector_boolean]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Draw the hyperplane with the updated parameters between the datapoints"
      ],
      "metadata": {
        "id": "Ezm1NsgB52pw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBo4lpqd3Rj1"
      },
      "source": [
        "plt.scatter(x_neg[:, 0], x_neg[:,1])\n",
        "plt.scatter(x_pos[:, 0], x_pos[:,1])\n",
        "X1 = np.linspace(0, 10, 11)\n",
        "X2 = (-b[0]-w[0]*X1)/w[1]\n",
        "plt.plot(X1, X2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X2))"
      ],
      "metadata": {
        "id": "z03qApdrIhEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FropYUI45jhH"
      },
      "source": [
        "Now, let us compare it to the Sklearn results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparing the outputs with the sklearn results"
      ],
      "metadata": {
        "id": "VbGQUl5urExx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is scikit learn?**\n",
        "\n",
        "* Scikit learn is a library used to perform machine learning in Python. Scikit learn is an open source machine learning library which is free software licensed and is reusable in various contexts, encouraging academic and commercial use.\n",
        "\n",
        "* Scikit-learn provides a range of supervised and unsupervised learning algorithms in Python.\n",
        "\n",
        "* It provides efficient tools for data analysis, data pre-processing, model building, model evaluation, and much more."
      ],
      "metadata": {
        "id": "LnyYtDkm6l2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to the follwing [link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) for the SVC classifier from sklearn"
      ],
      "metadata": {
        "id": "8jDdoz8e239u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNVFfB2Q6XNb"
      },
      "source": [
        "# Declaring the Support Vector Classifier\n",
        "clf = SVC(kernel = 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* First we start with importing the necessary classifier and creating an instance for it.\n",
        "\n",
        "* By using **fit()** we fit the classifier to the training points, which  is essentially the training part of the modeling process"
      ],
      "metadata": {
        "id": "Hs56Ci4N05cn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5HkfBP-6Yap"
      },
      "source": [
        "%%time\n",
        "clf.fit(X, y.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 3, 4, 5]\n",
        "b = [6, 7, 8, 9, 10]\n",
        "c = list(map(lambda x: sum(x), zip(a, b)))\n",
        "print(c)"
      ],
      "metadata": {
        "id": "5lzKyE1RNrOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI2ywEkn5g1I"
      },
      "source": [
        "print('w (coefficient) = ',clf.coef_)\n",
        "print('b (Intercept) = ',clf.intercept_)\n",
        "print('Indices of support vectors = ', clf.support_)\n",
        "print('Support vectors = ', clf.support_vectors_)\n",
        "print('Number of support vectors for each class = ', clf.n_support_)\n",
        "print('Coefficients of the support vector in the decision function = ', np.abs(clf.dual_coef_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constrained Optimization\n",
        "\n",
        "Constrained optimization problems are problems for which a function is to be minimized or maximized subject to constraints. Our constrained optimization problem is to maximize the function $f(x, y)$ while satisfying the constraint $g(x, y) = 0$ . maximize $f(x, y)$ subject to $g(x, y) = 0$. In some other scenarios, an optimization could be a minimization problem. minimize $f(x, y)$ subject to $g(x, y) = 0$"
      ],
      "metadata": {
        "id": "B3h-GZOoWwtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import solve"
      ],
      "metadata": {
        "id": "GPrRuoQ4W06W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lagrange multipliers and constrained optimization\n",
        "\n",
        "Recall why Lagrange multipliers are useful for constrained optimization - a stationary point must be where the constraint surface $g$ touches a level set of the function $f$ (since the value of $f$ does not change on a level set). At that point, $f$ and $g$ are parallel, and hence their gradients are also parallel (since the gradient is normal to the level set). So we want to solve\n",
        "\n",
        "<center>\n",
        "\n",
        "$ \\bigtriangledown f  = - λ \\bigtriangledown g$\n",
        "\n",
        "</center>\n",
        "\n",
        "or equivalently,\n",
        "\n",
        "<center>\n",
        "$ \\bigtriangledown f + λ \\bigtriangledown g = 0 $\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "<center>\n",
        "\n",
        "![image.png](https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/LagrangeMultipliers2D.svg/300px-LagrangeMultipliers2D.svg.png)\n",
        "\n",
        "Lagrange multipliers\n",
        "\n",
        "\n",
        "</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "oB0DgP4yYlO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Maximize the function $f(x,y,z) = xy + yz$  subject to the two constraints: $x + 2y = 6$ and $x − 3z = 0$."
      ],
      "metadata": {
        "id": "yVzIlCnac-DN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set up the equations\n",
        "\n",
        "<center>\n",
        "\n",
        "$F(x, y, z, λ, μ) = xy + yz − λ(x + 2y − 6) − μ(x − 3z)$\n",
        "\n",
        "<br>\n",
        "\n",
        "</center>\n",
        "\n",
        "Now set partial derivatives to zero and solve the following set of equations\n",
        "\n",
        "<center>\n",
        "\n",
        "\n",
        "\n",
        "$\\frac {∂F}{∂x} =  y − λ − μ = 0 $ \\\\\n",
        "\n",
        "$\\frac {∂F}{∂y} =  x + z − 2λ = 0 $ \\\\\n",
        "\n",
        "$\\frac {∂F}{∂z} =  y + 3μ = 0$ \\\\\n",
        "\n",
        "$\\frac {∂F}{∂λ} =  x + 2y − 6 = 0 $ \\\\\n",
        "\n",
        "$\\frac {∂F}{∂μ} =  x − 3z = 0 $ \\\\\n",
        "\n",
        "</center>\n",
        "\n",
        "<br>\n",
        "\n",
        "Plugging in the numbers and expressing in matrix form, we get which is a linear equation in $x, y, z, λ, μ$\n",
        "\n",
        "<center>\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{bmatrix}\n",
        "    0 & 1 & 0 & -1 & -1\\\\\n",
        "1 & 0 & 1 & -2 & 0\\\\\n",
        "0 & 1 & 0 & 0 & 3\\\\\n",
        "1 & 2 & 0 & 0 & 0\\\\\n",
        "1 & 0 & -3 & 0 & 0\n",
        "  \\end{bmatrix}\n",
        "  %\n",
        "  \\begin{bmatrix}\n",
        "    x \\\\\n",
        "    y \\\\\n",
        "    z \\\\\n",
        "    λ \\\\\n",
        "    μ\n",
        "  \\end{bmatrix}\n",
        "  %\n",
        "  =\n",
        "   \\begin{bmatrix}\n",
        "    0 \\\\\n",
        "    0 \\\\\n",
        "    0 \\\\\n",
        "    6 \\\\\n",
        "    0 \\\\\n",
        "  \\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k9Oyw6HidVEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the above obtained matrix\n",
        "A = np.array([\n",
        "    [0, 1, 0, -1, -1],\n",
        "    [1, 0, 1, -2, 0],\n",
        "    [0, 1, 0, 0, 3],\n",
        "    [1, 2, 0, 0, 0],\n",
        "    [1, 0,-3, 0, 0]])\n",
        "\n",
        "b = np.array([0,0,0,6,0])\n",
        "\n",
        "sol = solve(A, b)"
      ],
      "metadata": {
        "id": "G1A8Wubsc9aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sol)"
      ],
      "metadata": {
        "id": "4vakm4uEnOAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the original function\n",
        "def f(x, y, z):\n",
        "    return x * y + y * z"
      ],
      "metadata": {
        "id": "LXoQGpZWnYY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f(*sol[:3]))"
      ],
      "metadata": {
        "id": "7r1efbe8no0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmvdJ4aNmGjR"
      },
      "source": [
        "#@title Q.1. Use Lagrange multipliers to find the maxima and minima values of f(x, y) = 3x−4y subject to the constraint x^2+3y^2 = 129, if such values exist. { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer1 = \"Maxima = 11, Minima = -11\" #@param [\"\",\"Maxima = 11, Minima = -11\", \"Maxima = 48, Minima = -48\", \"Maxima = 43, Minima = -43\", \"Maxima = 24, Minima = -24\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX24XAeIJ6Nf"
      },
      "source": [
        "#@title Q.2. In Support Vector Machines, the problem of finding a separating hyperplane with the maximum margin (the optimal hyper plane) is a constrained optimization problem?  { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer2 = \"True\" #@param [\"\",\"True\", \"False\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}