{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083d726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
    "Id = \"2240589\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f43ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
    "password = \"9886499911\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a33a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run this cell to complete the setup for this Notebook\n",
    "from IPython import get_ipython\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ipython = get_ipython()\n",
    "\n",
    "notebook= \"M3_AST_24_Pretrained_models_for_Oxford_IIIT_pet_dataset_C\" #name of the notebook\n",
    "\n",
    "def setup():\n",
    "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/oxfordiitimage.zip\")\n",
    "    ipython.magic(\"sx unzip oxfordiitimage.zip\")\n",
    "    from IPython.display import HTML, display\n",
    "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
    "    print(\"Setup completed successfully\")\n",
    "    return\n",
    "\n",
    "def submit_notebook():\n",
    "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
    "\n",
    "    import requests, json, base64, datetime\n",
    "\n",
    "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
    "    if not submission_id:\n",
    "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
    "      r = requests.post(url, data = data)\n",
    "      r = json.loads(r.text)\n",
    "\n",
    "      if r[\"status\"] == \"Success\":\n",
    "          return r[\"record_id\"]\n",
    "      elif \"err\" in r:\n",
    "        print(r[\"err\"])\n",
    "        return None\n",
    "      else:\n",
    "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
    "        return None\n",
    "\n",
    "    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
    "      f = open(notebook + \".ipynb\", \"rb\")\n",
    "      file_hash = base64.b64encode(f.read())\n",
    "\n",
    "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
    "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
    "              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n",
    "              \"notebook\" : notebook,\n",
    "              \"feedback_experiments_input\" : Comments,\n",
    "              \"feedback_mentor_support\": Mentor_support}\n",
    "      r = requests.post(url, data = data)\n",
    "      r = json.loads(r.text)\n",
    "      if \"err\" in r:\n",
    "        print(r[\"err\"])\n",
    "        return None\n",
    "      else:\n",
    "        print(\"Your submission is successful.\")\n",
    "        print(\"Ref Id:\", submission_id)\n",
    "        print(\"Date of submission: \", r[\"date\"])\n",
    "        print(\"Time of submission: \", r[\"time\"])\n",
    "        print(\"View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\")\n",
    "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
    "        return submission_id\n",
    "    else: submission_id\n",
    "\n",
    "\n",
    "def getAdditional():\n",
    "  try:\n",
    "    if not Additional:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Additional\n",
    "  except NameError:\n",
    "    print (\"Please answer Additional Question\")\n",
    "    return None\n",
    "\n",
    "def getComplexity():\n",
    "  try:\n",
    "    if not Complexity:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Complexity\n",
    "  except NameError:\n",
    "    print (\"Please answer Complexity Question\")\n",
    "    return None\n",
    "\n",
    "def getConcepts():\n",
    "  try:\n",
    "    if not Concepts:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Concepts\n",
    "  except NameError:\n",
    "    print (\"Please answer Concepts Question\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# def getWalkthrough():\n",
    "#   try:\n",
    "#     if not Walkthrough:\n",
    "#       raise NameError\n",
    "#     else:\n",
    "#       return Walkthrough\n",
    "#   except NameError:\n",
    "#     print (\"Please answer Walkthrough Question\")\n",
    "#     return None\n",
    "\n",
    "def getComments():\n",
    "  try:\n",
    "    if not Comments:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Comments\n",
    "  except NameError:\n",
    "    print (\"Please answer Comments Question\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def getMentorSupport():\n",
    "  try:\n",
    "    if not Mentor_support:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Mentor_support\n",
    "  except NameError:\n",
    "    print (\"Please answer Mentor support Question\")\n",
    "    return None\n",
    "\n",
    "def getAnswer1():\n",
    "  try:\n",
    "    if not Answer1:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Answer1\n",
    "  except NameError:\n",
    "    print (\"Please answer Question 1\")\n",
    "    return None\n",
    "\n",
    "def getAnswer2():\n",
    "  try:\n",
    "    if not Answer2:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Answer2\n",
    "  except NameError:\n",
    "    print (\"Please answer Question 2\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def getId():\n",
    "  try:\n",
    "    return Id if Id else None\n",
    "  except NameError:\n",
    "    return None\n",
    "\n",
    "def getPassword():\n",
    "  try:\n",
    "    return password if password else None\n",
    "  except NameError:\n",
    "    return None\n",
    "\n",
    "submission_id = None\n",
    "### Setup\n",
    "if getPassword() and getId():\n",
    "  submission_id = submit_notebook()\n",
    "  if submission_id:\n",
    "    setup()\n",
    "else:\n",
    "  print (\"Please complete Id and Password cells before running setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c6517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,shutil,glob,PIL\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba9dbfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with mean and std\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.4839, 0.4528, 0.3962), (0.2702, 0.2655, 0.2745))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787dafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train set file\n",
    "train_data_folder = \"/content/oxfordiitimage/train\" # Train directory for loading images\n",
    "train_data = datasets.ImageFolder(root=train_data_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e97f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Loading the train dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac4501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a batches of images and labels\n",
    "train_images, train_labels = next(iter(train_loader))\n",
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d425aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels Translator\n",
    "label_names = {v: k for k, v in train_data.class_to_idx.items()}\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cce53bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of images along with their corresponding labels\n",
    "L = 3\n",
    "W = 3\n",
    "\n",
    "fig, axes = plt.subplots(L, W, figsize = (10, 10))\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "for i in np.arange(0, L*W):\n",
    "    axes[i].imshow(train_images[i].permute(1, 2, 0))\n",
    "    axes[i].set_title(label_names[train_labels[i].item()])\n",
    "    axes[i].axis('on')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d37cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = 0.0\n",
    "# for img, _ in train_data:\n",
    "#   mean += img.mean([1,2])\n",
    "# mean = mean/len(train_data)\n",
    "# print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b30670bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumel = 0.0\n",
    "# countel = 0\n",
    "# for img, _ in train_data:\n",
    "#     img = (img - mean.unsqueeze(1).unsqueeze(1))**2\n",
    "#     sumel += img.sum([1, 2])\n",
    "#     countel += torch.numel(img[0])\n",
    "# std = torch.sqrt(sumel/countel)\n",
    "# print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b72cd782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No of Categories\n",
    "len(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd9ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training samples\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e95dd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of one training image\n",
    "train_data[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc8be5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d098c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test whether GPU instance is present in the system of not.\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Using PyTorch version:', torch.__version__, 'CUDA:', use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a17be547",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "754fc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a51fae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 37)\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "066097ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "758f9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accu = []     # Empty list for saving train accuracy\n",
    "train_losses = []   # Empty list for saving train losses\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "  print('\\nEpoch : %d'%epoch)\n",
    "\n",
    "  model_ft.train()    # Initiate the model in training mode\n",
    "\n",
    "  running_loss=0\n",
    "  correct=0\n",
    "  total=0\n",
    "\n",
    "  # Loop through each batch of images in train set\n",
    "  for data in tqdm(train_loader):\n",
    "\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)   # Loading the input tensors into CUDA GPU\n",
    "\n",
    "    # Zero out the gradients from the preivous step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass (this calls the \"forward\" function within model_ft)\n",
    "    outputs = model_ft(inputs)\n",
    "\n",
    "    # Calculating the loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Back Propagation for calculaing gradients and adjusting weights\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # Picking the class/label with maximum probability\n",
    "    _, predicted = outputs.max(1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "  train_loss = running_loss/len(train_loader)     # Calculating the mean of training loss\n",
    "  accu = 100.*correct/total                       # Calculating the accuracy\n",
    "\n",
    "  train_accu.append(accu)\n",
    "  train_losses.append(train_loss)\n",
    "  print('Train Loss: %.3f | Accuracy: %.3f'%(train_loss,accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20d03542",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for epoch in range(1, epochs+1):\n",
    "  train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "834e5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/content/Oxford-IIIT-ResNet50.pth'\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad0f65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accu,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45e3bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train'])\n",
    "plt.title('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38c65c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/content/Oxford-IIIT-ResNet50.pth'\n",
    "model_ft.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39cc962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6bce0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testset\n",
    "test_data_folder = \"/content/oxfordiitimage/test\" # Train directory for loading images\n",
    "test_data = datasets.ImageFolder(root=test_data_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17d87265",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33313c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "j = 0\n",
    "\n",
    "# Loop through the test set\n",
    "for i, data in enumerate(test_loader):\n",
    "  input, label = data\n",
    "  # print(input.shape ,test_data.classes[label])\n",
    "\n",
    "  # Forward pass (this calls the \"forward\" function within model_ft)\n",
    "  output = model_ft(input.to(device))\n",
    "\n",
    "  # Output as max probability\n",
    "  pred = torch.max(output,1)\n",
    "\n",
    "  # Storing the actuals and the predictions\n",
    "  labels.append(test_data.classes[label])\n",
    "  predictions.append(test_data.classes[pred.indices])\n",
    "  if test_data.classes[pred.indices] == test_data.classes[label]:\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "901e7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j/len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fd44d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Labels'] = pd.Series(labels)\n",
    "results['Predictions'] = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd144dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a column to show whether prediction is Correct/Wrong\n",
    "results['Correct/Wrong'] = np.where((results['Labels'] == results['Predictions']) , \"Correct\", \"Wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaf51764",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"ResNet50_Predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7b554ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_prediction = results[results['Correct/Wrong'] == \"Wrong\"]\n",
    "wrong_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "756ad2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Correct/Wrong\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eeaf3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = results[results['Correct/Wrong'] == \"Correct\"]\n",
    "correct_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cba2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.googlenet(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs,37)\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fa3ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e2e7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accu = []     # Empty list for saving train accuracy\n",
    "train_losses = []   # Empty list for saving train losses\n",
    "def train(epoch):\n",
    "  print('\\nEpoch : %d'%epoch)\n",
    "\n",
    "  model_ft.train()    # Initiate the model in training mode\n",
    "\n",
    "  running_loss = 0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  for data in tqdm(train_loader):\n",
    "\n",
    "    inputs,labels=data[0].to(device),data[1].to(device)   # Loading the input tensors into CUDA GPU\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model_ft(inputs)\n",
    "    loss = criterion(outputs,labels)  # Calculating the loss\n",
    "    loss.backward()                   # Back Propagation for calculaing gradients and adjusting weights\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    _, predicted = outputs.max(1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "  train_loss = running_loss/len(train_loader)     # Calculating the mean of training loss\n",
    "  accu = 100.*correct/total                       # Calculating the accuracy\n",
    "\n",
    "  train_accu.append(accu)\n",
    "  train_losses.append(train_loss)\n",
    "  print('Train Loss: %.3f | Accuracy: %.3f'%(train_loss,accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff262dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for epoch in range(1, epochs+1):\n",
    "  train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2be46982",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/content/Oxford-IIIT-GoogleNet.pth'\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "496c22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accu,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c9aad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train'])\n",
    "plt.title('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bfc0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/content/Oxford-IIIT-GoogleNet.pth'\n",
    "model_ft.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d841cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f602396",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "j = 0\n",
    "for i,data in enumerate(test_loader):\n",
    "  input,label = data\n",
    "  output = model_ft(input.to(device))\n",
    "  pred = torch.max(output,1)\n",
    "  labels.append(test_data.classes[label])\n",
    "  predictions.append(test_data.classes[pred.indices])\n",
    "  if test_data.classes[pred.indices] == test_data.classes[label]:\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "885e5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j/len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e8c8240",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Labels'] = pd.Series(labels)\n",
    "results['Predictions'] = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ff7982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a column to show whether prediction is Correct/Wrong\n",
    "results['Correct/Wrong'] = np.where((results['Labels'] == results['Predictions']) , \"Correct\", \"Wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5a1ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"GoogleNet_Predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "241af8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_prediction = results[results['Correct/Wrong'] == \"Wrong\"]\n",
    "wrong_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14c239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Correct/Wrong\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca6fe904",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = results[results['Correct/Wrong'] == \"Correct\"]\n",
    "correct_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92942bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Q1. Which of the above statements is/are True regrading transfer learning?\n",
    "Answer1 = \"A, B, C and D\" #@param [\"\", \"Only A and B\", \"Only C and D\", \"Only A, B and D\", \"Only B, C and D\", \"Only A, B and C\", \"A, B, C and D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb70af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Q2. A problem with deep convolutional neural networks is that the number of feature maps often increases with the depth of the network. This problem can result in a dramatic increase in the number of parameters and computation required when larger filter sizes are used, such as 5×5 and 7×7. To address this problem, a 1×1 convolutional layer can be used that offers a channel-wise pooling, often called feature map pooling. This simple technique can be used for dimensionality reduction, decreasing the number of feature maps while retaining their salient features.\n",
    "Answer2 = \"FALSE\" #@param [\"\",\"TRUE\",\"FALSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3cd2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
    "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18bda94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
    "Additional = \"na\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c6cee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
    "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f1b9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
    "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3e803cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
    "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
