{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"another-optimum"},"source":["# Advanced Programme in Deep Learning (Foundations and Applications)\n","## A Program by IISc and TalentSprint\n","\n","### Kaggle Competition Notebook for Group Assignment: Face mask classification challenge using CNNs"]},{"cell_type":"markdown","metadata":{"id":"maritime-miami"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"nljJR6CwfZN_"},"source":["At the end of the mini-hackathon, you will be able to :\n","\n","* load and extract features of images\n","* build the convolutional neural networks\n","* use the pre-trained models of keras/Pytorch"]},{"cell_type":"markdown","metadata":{"id":"29152de7"},"source":["## Introduction\n","\n","This competition uses a Deep Neural Network, more specifically a Convolutional Neural Network, to differentiate between images of people, with masks, without masks and incorrectly placed masks. Manually built and pretrained networks will be used to perform this classification task.\n","\n","**Face-Mask-Detection-Using-CNN**\n","\n","* Outbreak of the Coronavirus pandemic has created various changes in the lifestyle of everyone around the world.\n","* Among these changes, wearing a mask has been very vital to every individual.\n","* Detection of people who are not wearing masks is a challenge due to the large populations.\n","* This face mask detection project can be used in schools, hospitals, banks, airports etc as a digitalized scanning tool.\n","  - The technique of detecting peopleâ€™s faces and segregating them into three classes namely the people with masks and people without masks and partial masks is done with the help of image processing and deep learning.\n","* With the help of this project, a person who is monitoring the face mask status for a particular firm can be seated in a remote area and still monitor efficiently and give instructions accordingly."]},{"cell_type":"markdown","metadata":{"id":"surprising-uruguay"},"source":["## Dataset\n","\n","The data for this mini-hackathon is collected from various sources including the masked images from internet and general frontal face images considered as without mask. This dataset consists of approximately 5059 train images and approximately 1300 validation and 660 test images with 3 classes `with_mask`, `without_mask` and `partial_mask`\n","\n","Many people are not correctly wearing their masks due to bad practices, bad behaviors or vulnerability of individuals (e.g., children, old people). For these reasons, several mask wearing campaigns intend to sensitize people about this problem and good practices. In this sense, this work proposes three types of masked face detection dataset; namely, the Correctly Masked Face, the Incorrectly Masked Face and their combination for the global masked face detection. This dataset serves the objective of classifying faces that are:\n","  \n","- Without Mask/ With Mask/ Partial Mask\n","  \n","Note that this dataset contains some annotated (artificially generated) masks to augment the 'masked' data category."]},{"cell_type":"markdown","metadata":{"id":"ih-oasWmdZul"},"source":["## Problem Statement"]},{"cell_type":"markdown","metadata":{"id":"qfWGmjNHdZul"},"source":["To build and implement a Convolutional Neural Network model to classify between masked/unmasked/partially masked faces."]},{"cell_type":"markdown","metadata":{"id":"DO2jS73oLnCR"},"source":["### 1. Create an API key in Kaggle.\n","\n","To do this, go to the competition site on Kaggle at (https://www.kaggle.com/t/cabf3c47d31844449b5b7079de3441d5) and click on user then click on your profile as shown below. Click Account.\n","\n","![alt text](https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Capture-NLP.PNG)"]},{"cell_type":"markdown","metadata":{"id":"CPTFW-C1NfaE"},"source":["### 2. Next, scroll down to the API access section and click on **Create New Token** to download an API key (kaggle.json).\n","\n","![alt text](https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Capture-NLP_1.PNG)"]},{"cell_type":"markdown","metadata":{"id":"WtETuXx8b-OC"},"source":["### 3. Upload your kaggle.json file using the following snippet in a code cell:\n","\n"]},{"cell_type":"code","metadata":{"id":"-1pfXBDxWl0Y"},"source":["from google.colab import files\n","files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCV_T6MMW4eX"},"source":["#If successfully uploaded in the above step, the 'ls' command here should display the kaggle.json file.\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JbukdzJ6cE32"},"source":["### 4. Install the Kaggle API using the following command\n"]},{"cell_type":"code","metadata":{"id":"dMj1n1MJcqzN"},"source":["!pip install -U -q kaggle==1.5.8"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Vpy9P1nchhd"},"source":["### 5. Move the kaggle.json file into ~/.kaggle, which is where the API client expects your token to be located:\n","\n"]},{"cell_type":"code","metadata":{"id":"yQbPsDOLZ0b4"},"source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BenAWlpI73sm"},"source":["#Execute the following command to verify whether the kaggle.json is stored in the appropriate location: ~/.kaggle/kaggle.json\n","!ls ~/.kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vm2jGsCradOS"},"source":["!chmod 600 /root/.kaggle/kaggle.json #run this command to ensure your Kaggle API token is secure on colab"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32unPZKzdI72"},"source":["### 6. Now download the Test Data from Kaggle"]},{"cell_type":"markdown","metadata":{"id":"ppuy5gRKHFwv"},"source":["**NOTE: If you get a '403 - Not Found' error after running the cell below, it is most likely that the user (whose kaggle.json is uploaded above) has not 'accepted' the rules of the competition and therefore has 'not joined' the competition.**"]},{"cell_type":"markdown","metadata":{"id":"41-ETZCE_A1j"},"source":["If you encounter **401-unauthorised** download latest **kaggle.json** by repeating steps 1 & 2"]},{"cell_type":"code","metadata":{"id":"TY40TmgfHq0s"},"source":["#If you get a forbidden link, you have most likely not joined the competition.\n","!kaggle competitions download -c challenge-on-face-masks-classification-using-cnns\n","!unzip /content/challenge-on-face-masks-classification-using-cnns.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"operating-latter"},"source":["## Grading = 10 Points"]},{"cell_type":"markdown","source":["## YOUR CODING STARTS FROM HERE"],"metadata":{"id":"QeKon2vruI_c"}},{"cell_type":"code","metadata":{"id":"812a816f"},"source":["#@title Run this cell to download the train data\n","!wget -qq https://cdn.extras.talentsprint.com/DLFA/Experiment_related_data/facemask_detection.zip\n","!unzip -qq facemask_detection.zip\n","print(\"Data Downloaded Successfuly!!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"abstract-stocks"},"source":["### Import Required packages"]},{"cell_type":"code","metadata":{"id":"YG52PDGENRgN"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"53g0zVbjRV7K"},"source":["### **Stage 1:** Data Loading and preprocessing of Images (2 points)"]},{"cell_type":"markdown","metadata":{"id":"aYSjwlcSGJq1"},"source":["#### Analyze the shape of images and distribution of classes"]},{"cell_type":"code","metadata":{"id":"Z_FC0knCfeFD"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vdQY-dzZeqWm"},"source":["#### Visualize the sample images of each class\n"]},{"cell_type":"code","metadata":{"id":"HCgAcqdGewsb"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkOr1nhNT5yD"},"source":["### **Stage 2:** Build and train the CNN model using Keras/Pytorch (3 points)\n","\n"]},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"RHP1TsTFbUwM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRL5GJodbRbt"},"source":["### **Stage 3:** Transfer learning (3 points)\n","\n","Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem.\n","\n","A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task.\n","\n","The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n","\n"]},{"cell_type":"markdown","source":["### Use the pre-trained models (VGG16, ResNet50, GoogleNet etc.)\n","\n","* Load the pre-trained model\n","* Train and evaluate the images"],"metadata":{"id":"IAKm9pm7bnwQ"}},{"cell_type":"code","metadata":{"id":"izxeDNkYbRbw"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Note:** Make a submission on kaggle using CNN model and Pre-trained model and then compare the model performance on the kaggle testset"],"metadata":{"id":"-PIejCLa8bOC"}},{"cell_type":"markdown","metadata":{"id":"k-O0Jx99UhmI"},"source":["###   **Stage 4**: Evaluate the Model and get model predictions on the Kaggle testset (2 Points)\n","\n","#### Expected accuracy: More than 90%\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"Sw9qtXxaahOt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fBIA1sbLByIL"},"source":["### Report Analysis\n","\n","- Compare the accuracies for the Pre-trained vs CNN models\n","- What process was followed to tune the hyperparameters?\n","- Plot the confusion matrix in terms of the misclassifications"]},{"cell_type":"markdown","metadata":{"id":"w4tF71VIUwzK"},"source":["### Capture the live image using the below code cell and predict"]},{"cell_type":"code","metadata":{"cellView":"form","id":"I6kTLnTmrcCg"},"source":["#@title Capture the photo\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename\n","\n","from IPython.display import Image\n","try:\n","  filename = take_photo()\n","  print('Saved to {}'.format(filename))\n","  display(Image(filename))\n","except Exception as err:\n","  print(str(err))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rNe9vDQ6q6Z6"},"source":["After executing above cell and capturing the photo, load the captured photo and predict with model.\n","\n","**Note:**\n","* Convert the image to numpy array and resize to the shape which model accept.\n","* Extend the dimension (to 4-D shape) of an image, as the model is trained on a batch of inputs."]},{"cell_type":"code","metadata":{"id":"XD5gr9YOAX83"},"source":["import PIL\n","from matplotlib import pyplot as plt\n","features = PIL.Image.open(\"photo.jpg\")\n","plt.imshow(features);\n","# YOUR CODE HERE to predict the image"],"execution_count":null,"outputs":[]}]}